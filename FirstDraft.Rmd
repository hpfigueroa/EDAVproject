---
title: 'First Draft Visualization Project'
author: 'Hernan Figueroa - Yufei Wu'
output: html_document
---
```{r setup, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      warning = FALSE,
                      message = FALSE,
                      fig.width = 10)
```
```{r libraries, echo=FALSE}
library(knitr)
library(tidyverse)
library(dplyr)
library(ggplot2)
```
### Introduction
Our project explores electricity consumption and electricity prices in different areas of New York City. We start exploring seasonality at the monthly and then weekly levels. We then compare prices vs consumption. The electric grid system in New York state is complex and the prices are not only dependend on consumption in New York City but also on prices from surrounding areas. 

The data were obtain from the [New York Independent System Operator (NYISO)](https://www.nyiso.com/):
- Load consumption data were obtained from a custom market report for real-time [Actual Load](https://www.nyiso.com/custom-reports?report=rt_actual_load)
- Price data was obtained from a custom market report for real-time [Local Market Price](https://www.nyiso.com/custom-reports?report=rt_lbmp_zonal)

NOTE: The ISO website does not allow a bulk download of more than 150,000 records. The dataset for each year has to be downloaded separately


### Analysis of data quality
Provide a detailed, well-organized description of data quality, including textual description, graphs, and code.

The datasets are time series for consumption (Load) and price (LBMP). These values are supposed to be recorded every 5 minutes. First we look at the raw information from the files undestand the data.

```{r rawLoad}
filename <- 'data/NYC_OASIS_Real_Time_Dispatch_Actual_Load_2017-2018.csv'
raw_load_df <- read.csv(filename, stringsAsFactors = FALSE)
glimpse(raw_load_df)
```
```{r rawPrice}
filename <- 'data/NYC_OASIS_Real_Time_Dispatch_Zonal_LBMP_2017-2018.csv'
raw_price_df <- read.csv(filename, stringsAsFactors = FALSE)
glimpse(raw_price_df)
```
Since we will focus on NYC data, we can drop the common variables Zone.Name and Zone.PTID from the data. From the price (LBMP) data, we only focus on the total price (`RTD.Zonal.LBMP`) and we can drop `RTD.Zonal.Losses`, `RTD.Zonal.Congestion` and `RTD.Zonal.Price.Version`.  We can convert `RTD.End.Time.Stamp` to `Time`. We should also make sure that `RTD.Actual.Load` and `RTD.Zonal.LBMP` are numeric values and label them as `Load` and `Price`. 

If values are recorded every 5 minutes, we expect 105,120 data points per year (12 values per hour times 8760 hour per year). Both dataset contain 106,607 and 106,188 observation, indicating that some values may be repeated. We create a sequence of time values to review the quality of the values in the time series.  
```{r ts_check}
ts_expected = seq(from=as.POSIXct("2017/11/01 00:05:00"),
                  to=as.POSIXct("2018/10/31 23:55:00"),
                  by=300) #sequence every 5 minutes (300 seconds)

raw_load_df$Time_Stamp <- as.POSIXct(raw_load_df$RTD.End.Time.Stamp, format="%Y/%m/%d %H:%M:%S")
raw_load_df <- subset(raw_load_df, Time_Stamp %in% ts_expected)

kable(x = data.frame(length(ts_expected), nrow(raw_load_df),
            sum(duplicated(raw_load_df$RTD.End.Time.Stamp)),
            length(unique(raw_load_df$Time_Stamp)),
            sum(is.na(raw_load_df))),
      col.names = c("Expected obs.", "Orig. obs.",
                    "Duplicated obs.", "unique expected obs.",
                    "NA observations"),
      caption = "Load dataset - Number of expected observations vs original number of observations")

raw_price_df$Time_Stamp <- as.POSIXct(raw_price_df$RTD.End.Time.Stamp, format="%Y/%m/%d %H:%M:%S")
raw_price_df <- subset(raw_price_df, Time_Stamp %in% ts_expected)

kable(x = data.frame(length(ts_expected), nrow(raw_price_df),
            sum(duplicated(raw_price_df$RTD.End.Time.Stamp)),
            length(unique(raw_price_df$Time_Stamp)),
            sum(is.na(raw_price_df))),
      col.names = c("Expected obs.", "Orig. obs.",
                    "Duplicated obs.", "unique expected obs.",
                    "NA observations"),
      caption = "Price dataset - Number of expected observations vs original number of observations")
```  

Now that we understand the structure of the dataset, we will create a function to read the yearly files and only load the load and price information. 
```{r smooth}
read.NYISO.Load <- function(filename){
  NYCLoad_df <- read.csv(filename, 
                        colClasses =c("character",
                                      rep("NULL",2),
                                      "character"),
                        stringsAsFactors = FALSE,
                        na=c("NA"))
  colnames(NYCLoad_df) <- c("Time_Stamp","Actual_Load")
  NYCLoad_df <- NYCLoad_df[1:(nrow(NYCLoad_df)-1),] #Last value belongs to next month
  ts_expected = seq(from=as.POSIXct(NYCLoad_df$Time_Stamp[1]),
                  to=as.POSIXct(NYCLoad_df$Time_Stamp[nrow(NYCLoad_df)]),
                  by=300) #sequence every 5 minutes (300 seconds)
  NYCLoad_df$Time_Stamp <- as.POSIXct(NYCLoad_df$Time_Stamp, format="%Y/%m/%d %H:%M:%S")
  NYCLoad_df <- subset(NYCLoad_df, Time_Stamp %in% ts_expected)
  NYCLoad_df <- subset(NYCLoad_df, !duplicated(NYCLoad_df$Time_Stamp))
  NYCLoad_df$YMonth <- as.factor(format(NYCLoad_df$Time_Stamp,"%Y-%m"))
  NYCLoad_df$Actual_Load <- as.numeric(NYCLoad_df$Actual_Load)
  return(na.omit(NYCLoad_df))
}
read.NYISO.Price <- function(filename){
  NYCPrice_df <- read.csv(filename, 
                        colClasses =c("character",
                                      rep("NULL",2),
                                      "character",
                                      rep("NULL",3)),
                        stringsAsFactors = FALSE,
                        na=c("NA"))
  colnames(NYCPrice_df) <- c("Time_Stamp","Actual_Price")
  NYCPrice_df <- NYCPrice_df[1:(nrow(NYCPrice_df)-1),] #Last value belongs to next month
  ts_expected = seq(from=as.POSIXct(NYCPrice_df$Time_Stamp[1]),
                  to=as.POSIXct(NYCPrice_df$Time_Stamp[nrow(NYCPrice_df)]),
                  by=300) #sequence every 5 minutes (300 seconds)
  NYCPrice_df$Time_Stamp <- as.POSIXct(NYCPrice_df$Time_Stamp, format="%Y/%m/%d %H:%M:%S")
  NYCPrice_df <- subset(NYCPrice_df, Time_Stamp %in% ts_expected)
  NYCPrice_df <- subset(NYCPrice_df, !duplicated(NYCPrice_df$Time_Stamp))
  NYCPrice_df$YMonth <- as.factor(format(NYCPrice_df$Time_Stamp,"%Y-%m"))
  NYCPrice_df$Actual_Price <- as.numeric(NYCPrice_df$Actual_Price)
  return(na.omit(NYCPrice_df)) #We drop a few NA values
}

```   

With those functions we can read the datasets
```{r read_data}
dfl2018 <- read.NYISO.Load("./data/NYC_OASIS_Real_Time_Dispatch_Actual_Load_2017-2018.csv")
dfl2017 <- read.NYISO.Load("./data/NYC_OASIS_Real_Time_Dispatch_Actual_Load_2016-2017.csv")
dfl2016 <- read.NYISO.Load("./data/NYC_OASIS_Real_Time_Dispatch_Actual_Load_2015-2016.csv")
dfl2015 <- read.NYISO.Load("./data/NYC_OASIS_Real_Time_Dispatch_Actual_Load_2014-2015.csv")
dfp2018 <- read.NYISO.Price("./data/NYC_OASIS_Real_Time_Dispatch_Zonal_LBMP_2017-2018.csv")
dfp2017 <- read.NYISO.Price("./data/NYC_OASIS_Real_Time_Dispatch_Zonal_LBMP_2016-2017.csv")
dfp2016 <- read.NYISO.Price("./data/NYC_OASIS_Real_Time_Dispatch_Zonal_LBMP_2015-2016.csv")
dfp2015 <- read.NYISO.Price("./data/NYC_OASIS_Real_Time_Dispatch_Zonal_LBMP_2014-2015.csv")
```

### **V1 - Monthly Average Consumption in NYC in 2018**
After exploring the datasets, we only read the time and load column. We can see that most data falls within the expected time stamps.
reading the dataset, we change the column Higher in the summer months due to AC usage. 
```{r 1v1}
mean_monthly <- function(dflyear) {
  return(dflyear %>%
         group_by(YMonth) %>%
         summarise(AvgLoad = mean(Actual_Load))
        )
}
gv1 <- ggplot(mean_monthly(dfl2018), aes(YMonth,AvgLoad)) +
  geom_col() +
  ylab("")
gv1

```

### **V2 - Histogram of Consumption in NYC in 2018**
The summer months show some high values and more spreaded distributions. It may be more informative than V1
```{r 1v2}
gv2 <- ggplot(data = dfl2018, aes(Actual_Load)) +
  geom_histogram(fill = "red", binwidth = 100) +
  facet_wrap(~YMonth)
gv2
```

### **Is there seasonality in electricity consumption?**

NOTE: The ISO website does not allow a bulk download of more than 150,000 records. Each year has to be downloaded separately
```{r 1v3}
Load_mean_2015 <- mean_monthly(dfl2015)
Load_mean_2016 <- mean_monthly(dfl2016)
Load_mean_2017 <- mean_monthly(dfl2017)
Load_mean_2018 <- mean_monthly(dfl2018)

levels(Load_mean_2015$YMonth) <- month.abb[c(11:12,1:10)]
levels(Load_mean_2016$YMonth) <- month.abb[c(11:12,1:10)]
levels(Load_mean_2017$YMonth) <- month.abb[c(11:12,1:10)]
levels(Load_mean_2018$YMonth) <- month.abb[c(11:12,1:10)]

Load_mean_2015$Year <- "2015"
Load_mean_2016$Year <- "2016"
Load_mean_2017$Year <- "2017"
Load_mean_2018$Year <- "2018"
Load_mean_df <- rbind(Load_mean_2015,Load_mean_2016,Load_mean_2017,Load_mean_2018)

gv3 <- ggplot(Load_mean_df, aes(YMonth, AvgLoad, color=Year)) + geom_point(size=4) + 
    ggtitle("Average Electricity Consumption in NYC") +
    labs (x = "", y = "MWh") +
    theme_grey(16) +
    theme(legend.title = element_blank())
gv3
```